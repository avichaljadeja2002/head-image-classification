About the project:
Our project consists of a bunch of images, jupyter notebook files, and python files.

faces4 is the original dataset from Carnegie Mellon: https://archive.ics.uci.edu/dataset/124/cmu+face+images
faces is the dataset we used and then augmented. faces4 were in a weird format that we changed to .png in faces.

brightness_batch - changes the brightness
script_to_flip - flips the image
rotate_batch - rotates the image 
greyscale_to_colour_script - converts greyscale image to RGB

Any file that ends in _model.h5 is the saved version of our model, so you don't need to retrain.

All of the models follow the same structure. It is very straightforward if you want to add classes to 
the different maps. 
---------------------------------------------------------------------------
Instructions on how to run:
website link: https://ad9f-137-112-225-48.ngrok-free.app/

The website is very simple, just upload the image and hit the button to run.

Our statistics for the individual classifiers using the training/testing split that Dr. Boutell mentioned:
Sunglasses Classifier on 20 epochs: 96.0%
Head Orientation Classifier on 30 epochs: 92.4%
Emotion Classifier on 30 epochs: 91.9%
